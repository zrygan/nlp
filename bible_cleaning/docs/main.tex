\documentclass{article}
\usepackage{hyperref}
\usepackage{amsmath, amssymb, listings, cleveref, graphicx}
\usepackage{pdflscape}
\usepackage{tablefootnote}
\usepackage[edges]{forest}
\usepackage{todonotes}
\usepackage{xcolor}

\input{assets/listing.tex}

\title{Construction of Biblical Corpora by Web Scraping and Extraction}
\author{Zhean Ganituen}
\date{\today}

\begin{document}
\maketitle
\tableofcontents

\section{Data Selection}

\subsection{Philippine Languages}

The goal of the project is to construct a corpus from the translations of The
Bible in \( n = 16 \) different Philippine Languages. The selected Philippine
languages are enumerated in~\cref{tab:ph_languages}.

\begin{table}[h!]
    \centering
    \begin{tabular}{lc}
        \hline
        \textbf{Philippine Language} & \textbf{ISO 639} \\
        \hline
        Tagalog                      & \texttt{tgl}     \\
        Cebuano                      & \texttt{ceb}     \\
        Ilocano                      & \texttt{ilo}     \\
        Hiligaynon                   & \texttt{hil}     \\
        Bikol language~\footnotemark & \texttt{bik}     \\
        Waray-Waray                  & \texttt{war}     \\
        Kapampangan                  & \texttt{pam}     \\
        Pangasinan                   & \texttt{pag}     \\
        Adasen                       & \texttt{tiu}     \\
        Chavacano                    & \texttt{cbk}     \\
        Paranan                      & \texttt{prf}     \\
        Tausug                       & \texttt{tsg}     \\
        Romblomanon                  & \texttt{rol}     \\
        Masbatenyo                   & \texttt{msb}     \\
        Kinaray-a                    & \texttt{krj}     \\
        Yami language                & \texttt{tao}     \\
        \hline
    \end{tabular}
    \caption{Philippine languages with their ISO 639 codes}\label{tab:ph_languages}
\end{table}
\footnotetext{The code \texttt{bcl} is also used for the Bikol language.}

To allow for the corpus to be inclusive and enclose a large array of
Austronsian sub-groups

These languages were selected in such a way that allows for the corpus to be
inclusive and enclose a large array of Austronesian sub-groups. The language
family or phylogenic tree of the sample languages are
on~\cref{fig:phylo_tree,fig:chavacano_phylo}. As an aside Chavacano is a
Spanish-based creole (hence, it is not Austronesian) while the Yami language is
a language of the Taiwanese indigenous people.~\todo{ Maybe add more
    information here? /zrygan/}

The ISO 639 codes and the Language families are from Ethnologue~\cite{ESF25}.
\newpage \thispagestyle{empty} \input{assets/phylogenic_tree.tex} \newpage% removes page number for this page

\subsection{Biblical Text}

The online Bible platform YouVersion (previously known as Bible.com or Bible
App) was used as the source of biblical text. To ensure a sufficiently large
corpus for each language, we set the minimum corpus size (\( |C| \)) to be
50,000 tokens. the complete English Bible contains approximately 760,000 words,
this threshold is suitable because some translations are incomplete or still in
progress~\cite{JJS11}. Examples of unfinished translations include those for
the Tausug, Paranan, and Masbatenyo languages.

\begin{table}[h!]
    \centering
    \begin{tabular}{ll}
        \hline
        \textbf{Language} & \textbf{URL (to Genesis 1)}                           \\
        \hline
        Tagalog           & \url{https://www.bible.com/bible/2195/GEN.1.ABTAG01}  \\
        Cebuano           & \url{https://www.bible.com/bible/562/GEN.1.RCPV}      \\
        Ilokano           & \url{https://www.bible.com/bible/782/GEN.1.RIPV}      \\
        Hiligaynon        & \url{https://www.bible.com/bible/2190/GEN.1.MBBHIL12} \\
        Bikol             & \url{https://www.bible.com/bible/890/GEN.1.MBBBIK92}  \\
        Waray-Waray       & \url{https://www.bible.com/bible/2198/GEN.1.MBBSAM}   \\
        Kapampangan       & \url{https://www.bible.com/bible/1141/GEN.1.PMPV}     \\
        Pangasinan        & \url{https://www.bible.com/bible/2194/GEN.1.MBBPAN83} \\
        Adasen            & \url{https://www.bible.com/bible/2812/MAT.1.YBT}      \\
        Chavacano         & \url{https://www.bible.com/bible/1129/MAT.1.CBKNT}    \\
        Paranan           & \url{https://www.bible.com/bible/438/MAT.1.PRF}       \\
        Tausug            & \url{https://www.bible.com/bible/1319/MAT.1.TSG}      \\
        Romblomanon       & \url{https://www.bible.com/bible/2244/MAT.1.BKR}      \\
        Masbatenyo        & \url{https://www.bible.com/bible/1222/MAT.1.MSB}      \\
        Kinaray-a         & \url{https://www.bible.com/bible/1489/MAT.1.KRJNT}    \\
        Yami language     & \url{https://www.bible.com/bible/2364/MAT.1.SNT}      \\
        \hline
    \end{tabular}
    \caption{Links to Genesis/Mathew translations in various languages.}
\end{table}

\section{Corpus Construction}

The source code of the methodology may be accessed in this GitHub repository:
\url{https://github.com/zrygan/zrygan.nlp/tree/master/bible_cleaning}

\subsection{Web Scraping and Parsing}

\todo{this is very rough, will work on this more}

Since YouVersion is an online platform written in the Hypertext Markup Language
(HTML). We started by analyzing the structure of each webpage, pinning down the
location of the biblical content in each page.

From this, we determined that all spans with \texttt{ChapterContent\_verse\_\_}
as the prefix of its class is biblical text.

\begin{lstlisting}[language=HTML, caption={\texttt{ChapterContent\_verse\_\_} tag}, label={list:chapter_content}]
<span 
    data-usfm="GEN.1.1"
    class="ChapterContent_verse__57FIw">
    
    <span class="ChapterContent_label__R2PLt">
        1
    </span>
    
    <span class="ChapterContent_content__RrUqA">
        Nang pasimula, nilikha ng Diyos ang
        langit
    </span>
    
    <span class="ChapterContent_note__YlDW0">
        <!-- content note -->
    </span>
    
    <span class="ChapterContent_content__RrUqA">
        at ang lupa.
    </span>
</span>
\end{lstlisting}

In \cref{list:chapter_content}, the text inside the desired tag are extracted
while the rest are disregarded. An example of which is the
\texttt{CharcterContent\_note\_} tag which are notes provided by YouVersion to
the reader.

Therefore, after scraping the HTML webpages we need to parse these sections to
extract the desired information for the biblical corpora.

To make the solution efficient, the web scraping and parsing step occur
simultaneously. The web scraper uses the Colly framework for Go (or Golang).
While the parsing uses a combination of string search functions (looking for
the \texttt{ChapterContent\_verse\_\_} tag) and regular expressions for
cleaning.

\begin{lstlisting}[language=Go, caption={Parsing and Cleaning Step}, label={list:parse_and_clean}]
c := colly.NewCollector()

c.OnHTML("span[class^='ChapterContent_verse__']", func(e *colly.HTMLElement) {
    verseNumber := e.ChildText("span[class^='ChapterContent_label__']")
    verseNumber = regexp.MustCompile(`\D`).ReplaceAllString(verseNumber, "")
    var verseTexts []string
    e.DOM.Find("span[class^='ChapterContent_content__']").Each(func(_ int, s *goquery.Selection) {
        text := strings.TrimSpace(s.Text())
        if text != "" {
            clean := text
            for _, re := range cleaningRes {
                clean = re.ReplaceAllString(clean, "")
            }
            if clean != "" {
                verseTexts = append(verseTexts, clean)
            }
        }
    })
    if len(verseTexts) > 0 {
        verses = append(verses, fmt.Sprintf("%s: %s", verseNumber, strings.Join(verseTexts, " ")))
    }
})
\end{lstlisting}

On~\cref{list:parse_and_clean}, we scrape the HTML source code and find all
instances of the desired tag. We then extract and clean the contents within
that tag. The code uses a couple of regular expressions (RE) for cleaning which are
enumerated in~\cref{tab:regex}.

\begin{table}[h!]
    \centering
    \begin{tabular}{p{\dimexpr0.5\linewidth\relax} p{\dimexpr0.4\linewidth\relax}}
        \hline
        \textbf{Regular Expression (RE)} & \textbf{Purpose} \\
        \hline
        \verb|[^a-zA-Z0-9\s\.\,\;\:\!\?\'\"-]+| & Remove all characters that are not letters, digits, whitespace, or basic punctuation. \\
        \verb|[:\s]+$| & Match one or more colons or spaces at the end of a line. \\
        \verb|^[\d#:\s]+| & Remove leading numbers, hashes, colons, or spaces at the start of a line. \\
        \hline
    \end{tabular}
    \caption{REs used for text cleaning}\label{tab:regex}
\end{table}

To allow for the algorithm to continuously run, we now needed to find the location of
the next Bible chapter in the webpage. Again, the approach is straightforward and we 
simply needed to determine the tag or class containing the hyperlink to the next page.

We found that any \texttt{<a>} tag with the \texttt{href} leading to a \texttt{/bible/}
page are navigation buttons. So, we simply created a \texttt{visited} hash table 
containing all visited hyperlinks. And all \texttt{<a>} tags are cross-referenced with 
that hash table. Excerpts of this routine are found in~\cref{list:next_chap,list:open_next}

\begin{lstlisting}[language=Go, caption={Finding the next chapter using the HTML tags}, label={list:next_chap}]
c := colly.NewCollector()

c.OnHTML("a[href^='/bible/']", func(e *colly.HTMLElement) {
    title := e.DOM.Find("svg title").Text()
    if title == "Next Chapter" {
        nextURL = "https://www.bible.com" + e.Attr("href")
    }
})    
\end{lstlisting}

\begin{lstlisting}[language=Go, caption={Opening the next chapter}, label={list:open_next}]
if nextURL != "" && !visited[nextURL] {
    wordCount += ScrapeAndParse(nextURL,
    language,
    outputDir, cleaningRes,
    visited,
    chapterCounter,
    maxCount,
    )
}
\end{lstlisting}

Finally, concurrency was used to make the algorithm efficient.

\todo{Add segmentation}

\section{Parallel Corpus}

\bibliography{refs}
\bibliographystyle{alpha}

\vfill
{\footnotesize
    \noindent\textbf{Declaration of AI Use:} The author used ChatGPT-5 to 
    assist with language editing and improving the clarity of the manuscript. 
    All content generated by the AI was carefully reviewed and edited by the 
    authors. The authors take full responsibility for the accuracy and integrity 
    of the final manuscript.
    \par}

\end{document}